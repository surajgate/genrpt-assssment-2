from typing import TypedDict, Optional, Literal
from langgraph.graph import END, StateGraph

# Import your existing chains
from sql_chain import (
    answer_question_via_database,
    get_sql_confidence_score
)
from pdf_response_chain import generate_answer_from_pdf_context
from user_query_rephrasing import generate_rephrased_query


class RouterState(TypedDict):
    """Represents the state shared between nodes in the router workflow.

    Attributes:
        original_question: The original question asked by the user.
        current_question: The current version of the question (original or rephrased).
        sql_answer: Answer generated by the SQL chain.
        sql_query: SQL query generated and executed.
        sql_confidence: Confidence score of the SQL answer.
        pdf_answer: Answer generated from PDF documents.
        pdf_confidence: Confidence score of the PDF answer.
        final_answer: Final answer selected for the user.
        attempted_rephrase: Whether the original question has already been rephrased.
        rephrased_question: The rephrased version of the question (if any).
        next_step: The next step to take in the workflow.
    """
    original_question: str
    current_question: str
    sql_answer: Optional[str]
    sql_query: Optional[str]
    sql_confidence: Optional[float]
    pdf_answer: Optional[str]
    pdf_confidence: Optional[float]
    final_answer: Optional[str]
    attempted_rephrase: bool
    rephrased_question: Optional[str]
    next_step: Optional[Literal["select_final_answer", "rephrase_question"]]


CONFIDENCE_THRESHOLD = 0.7


def execute_both_chains(state: RouterState) -> RouterState:
    """Runs both the SQL and PDF chains to get parallel answers.

    Args:
        state: The current state including the user's question.

    Returns:
        Updated state including both SQL and PDF answers and their confidence scores.
    """
    question = state["current_question"]

    # Execute SQL chain
    sql_question, sql_query, sql_answer = answer_question_via_database(
        question)
    sql_confidence = get_sql_confidence_score(
        sql_question, sql_query, sql_answer)

    # Execute PDF chain
    pdf_answer, pdf_confidence = generate_answer_from_pdf_context(question)

    return {
        "sql_answer": sql_answer,
        "sql_query": sql_query,
        "sql_confidence": sql_confidence,
        "pdf_answer": pdf_answer,
        "pdf_confidence": pdf_confidence,
        "current_question": question,
        "next_step": None  # Clear any previous next_step
    }


def evaluate_results(state: RouterState) -> RouterState:
    """Evaluates the confidence of answers and decides next step.

    Returns:
        Updated state with next_step set based on confidence evaluation.
    """
    max_confidence = max(state.get("sql_confidence", 0),
                         state.get("pdf_confidence", 0))

    if max_confidence >= CONFIDENCE_THRESHOLD or state["attempted_rephrase"]:
        return {"next_step": "select_final_answer"}
    else:
        return {"next_step": "rephrase_question"}


def rephrase_question(state: RouterState) -> RouterState:
    """Rephrases the original question and prepares the state for a retry.

    Args:
        state: The current router state.

    Returns:
        Updated state with rephrased question and reset answer fields.
    """
    rephrased = generate_rephrased_query(state["original_question"])

    return {
        "current_question": rephrased,
        "attempted_rephrase": True,
        "rephrased_question": rephrased,
        "sql_answer": None,
        "sql_query": None,
        "sql_confidence": None,
        "pdf_answer": None,
        "pdf_confidence": None,
        "next_step": None
    }


def select_final_answer(state: RouterState) -> RouterState:
    """Selects the best answer based on confidence scores from SQL and PDF chains.

    Args:
        state: The current router state.

    Returns:
        Updated state with the selected final answer.
    """
    sql_conf = state.get("sql_confidence", 0)
    pdf_conf = state.get("pdf_confidence", 0)

    if sql_conf >= pdf_conf and sql_conf > 0:
        return {"final_answer": state["sql_answer"]}
    elif pdf_conf > 0:
        return {"final_answer": state["pdf_answer"]}
    else:
        return {"final_answer": "Sorry, I couldn't find a confident answer to your question."}


def create_router_workflow():
    """Builds and compiles the router agent workflow using LangGraph.

    Returns:
        A compiled workflow that executes SQL/PDF chains, rephrases questions, and selects the best answer.
    """
    workflow = StateGraph(RouterState)

    # Define nodes
    workflow.add_node("execute_both_chains", execute_both_chains)
    workflow.add_node("evaluate_results", evaluate_results)
    workflow.add_node("rephrase_question", rephrase_question)
    workflow.add_node("select_final_answer", select_final_answer)

    # Define transitions
    workflow.add_edge("execute_both_chains", "evaluate_results")

    # Conditional edge based on next_step
    workflow.add_conditional_edges(
        "evaluate_results",
        lambda state: state.get("next_step", "select_final_answer"),
        {
            "select_final_answer": "select_final_answer",
            "rephrase_question": "rephrase_question"
        }
    )

    workflow.add_edge("rephrase_question", "execute_both_chains")
    workflow.add_edge("select_final_answer", END)

    # Set entry point
    workflow.set_entry_point("execute_both_chains")

    return workflow.compile()


# Create the workflow instance
router_workflow = create_router_workflow()


def answer_question(question: str) -> dict:
    """Handles user questions using the router workflow and returns final response.

    Args:
        question: The user's original question.

    Returns:
        A dictionary containing:
        - answer: The final response
        - source: Which data source provided the answer ('sql' or 'pdf')
        - confidence: The confidence score (0-1)
        - was_rephrased: Boolean indicating if question was rephrased
        - original_question: The initial user question
        - final_question: The question version that produced the answer
        - sql_query: The generated SQL query (if SQL source was used)
    """
    initial_state = {
        "original_question": question,
        "current_question": question,
        "sql_answer": None,
        "sql_query": None,
        "sql_confidence": None,
        "pdf_answer": None,
        "pdf_confidence": None,
        "final_answer": None,
        "attempted_rephrase": False,
        "rephrased_question": None,
        "next_step": None
    }

    result = router_workflow.invoke(initial_state)

    # Determine which source provided the answer
    source = "none"
    if result.get("sql_confidence", 0) > result.get("pdf_confidence", 0):
        source = "sql"
    elif result.get("pdf_confidence", 0) > 0:
        source = "pdf"

    return {
        "answer": result["final_answer"],
        "source": source,
        "confidence": max(result.get("sql_confidence", 0), result.get("pdf_confidence", 0)),
        "was_rephrased": result["attempted_rephrase"],
        "original_question": result["original_question"],
        "final_question": result["current_question"],
        "sql_query": result.get("sql_query")
    }
